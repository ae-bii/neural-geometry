{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.learning import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Kernel, _check_length_scale\n",
    "from skopt.acquisition import gaussian_ei\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from typing import List, Tuple, Any\n",
    "import searchspace\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading MNIST data into into training, validation, and testing datasets\n",
    "mnist_train = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# We split 5000/60000 of the data points from training to validation\n",
    "# We end up with 55000 training, 5000, validation, and 10000 testing points\n",
    "mnist_train, mnist_val = torch.utils.data.random_split(mnist_train, [55000, 5000])\n",
    "\n",
    "mnist_test = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph search space\n",
    "graph, idxs = searchspace.define_space_search_graph(['E2', 'S2', 'H2'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(params: Any) -> float:\n",
    "    # TODO: compare learned encoder latent space to that of chosen product space?\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function with validation metric\n",
    "def objective_function(params: Any) -> float:\n",
    "    # Train the neural network with the given parameters\n",
    "    validation_metric = train_neural_network(params)\n",
    "    return validation_metric  # Minimize the negative of the validation metric\n",
    "\n",
    "# Compute the Laplacian matrix of the graph\n",
    "def get_laplacian_matrix(graph: nx.Graph) -> np.ndarray:\n",
    "    # Convert the graph to an adjacency matrix\n",
    "    adjacency_matrix = nx.adjacency_matrix(graph).toarray()\n",
    "    \n",
    "    # Compute the degree matrix\n",
    "    degree_matrix = np.diag(np.sum(adjacency_matrix, axis=1))\n",
    "    \n",
    "    # Compute the Laplacian matrix: L = D - A\n",
    "    laplacian = degree_matrix - adjacency_matrix\n",
    "    \n",
    "    return laplacian\n",
    "\n",
    "# Perform eigendecomposition of the Laplacian matrix\n",
    "def get_eigendecomposition(laplacian: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Compute eigendecomposition: L = U * Lambda * U^T\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(laplacian)\n",
    "    return eigenvectors, np.diag(eigenvalues)\n",
    "\n",
    "# Define the covariance matrix of the GP\n",
    "def compute_covariance_matrix(eigenvectors: np.ndarray, eigenvalues: np.ndarray, beta: float) -> np.ndarray:\n",
    "    # Define the covariance matrix: U * e^(-beta * Lambda) * U^T\n",
    "    covariance_matrix = np.dot(eigenvectors, np.dot(np.exp(-beta * eigenvalues), eigenvectors.T))\n",
    "    return covariance_matrix\n",
    "\n",
    "# Create custom kernel for the GP\n",
    "# https://stackoverflow.com/questions/49188159/how-to-create-a-custom-kernel-for-a-gaussian-process-regressor-in-scikit-learn\n",
    "# https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/gaussian_process/kernels.py#L165\n",
    "class LaplacianGPKernel(Kernel):\n",
    "    def __init__(self, laplacian_matrix: np.ndarray, beta: float = 1.0):\n",
    "        self.laplacian_matrix = laplacian_matrix\n",
    "        self.beta = beta\n",
    "\n",
    "    def __call__(self, X: np.ndarray, Y: np.ndarray = None) -> np.ndarray:\n",
    "        if Y is None:\n",
    "            Y = X\n",
    "        # Compute the Laplacian-based covariance matrix\n",
    "        v, e = get_eigendecomposition(X)\n",
    "        K = compute_covariance_matrix(v, e, self.beta)\n",
    "        return K\n",
    "\n",
    "    def diag(self, X: np.ndarray) -> np.ndarray:\n",
    "        return np.ones(X.shape[0])\n",
    "\n",
    "    def is_stationary(self) -> bool:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dimension 0. See the documentation of check_dimension for supported values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Run bayesian optimization\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Perform Bayesian optimization step with Expected Improvement\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mobjective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Get the next node to evaluate\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     next_node \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m~/Documents/cs-stuff/nlgm-implementation/.venv/lib/python3.11/site-packages/skopt/optimizer/gp.py:271\u001b[0m, in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Check params\u001b[39;00m\n\u001b[1;32m    270\u001b[0m rng \u001b[38;5;241m=\u001b[39m check_random_state(random_state)\n\u001b[0;32m--> 271\u001b[0m space \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_dimensions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m         space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[1;32m    277\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[1;32m    278\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    279\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/cs-stuff/nlgm-implementation/.venv/lib/python3.11/site-packages/skopt/utils.py:591\u001b[0m, in \u001b[0;36mnormalize_dimensions\u001b[0;34m(dimensions)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_dimensions\u001b[39m(dimensions):\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a ``Space`` where all dimensions are normalized to unit range.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m    This is particularly useful for Gaussian process based regressors and is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m         dimensions.\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m     space \u001b[38;5;241m=\u001b[39m \u001b[43mSpace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     transformed_dimensions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dimension \u001b[38;5;129;01min\u001b[39;00m space\u001b[38;5;241m.\u001b[39mdimensions:\n",
      "File \u001b[0;32m~/Documents/cs-stuff/nlgm-implementation/.venv/lib/python3.11/site-packages/skopt/space/space.py:951\u001b[0m, in \u001b[0;36mSpace.__init__\u001b[0;34m(self, dimensions, constraint)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dimensions, constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcheck_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dimensions, Space):\n\u001b[1;32m    953\u001b[0m         constraint \u001b[38;5;241m=\u001b[39m dimensions\u001b[38;5;241m.\u001b[39mconstraint\n",
      "File \u001b[0;32m~/Documents/cs-stuff/nlgm-implementation/.venv/lib/python3.11/site-packages/skopt/space/space.py:951\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dimensions, constraint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions \u001b[38;5;241m=\u001b[39m [\u001b[43mcheck_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m dimensions]\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dimensions, Space):\n\u001b[1;32m    953\u001b[0m         constraint \u001b[38;5;241m=\u001b[39m dimensions\u001b[38;5;241m.\u001b[39mconstraint\n",
      "File \u001b[0;32m~/Documents/cs-stuff/nlgm-implementation/.venv/lib/python3.11/site-packages/skopt/space/space.py:96\u001b[0m, in \u001b[0;36mcheck_dimension\u001b[0;34m(dimension, transform)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_dimension\u001b[39m(dimension, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Turn a provided dimension description into a dimension object.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    Checks that the provided dimension falls into one of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m        Dimension instance.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     old_dim \u001b[38;5;241m=\u001b[39m \u001b[43m_check_dimension_old\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m warning_list:\n",
      "File \u001b[0;32m~/Documents/cs-stuff/nlgm-implementation/.venv/lib/python3.11/site-packages/skopt/space/space.py:159\u001b[0m, in \u001b[0;36m_check_dimension_old\u001b[0;34m(dimension, transform)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dimension\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dimension, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdimension\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m. See the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocumentation of check_dimension for supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# A `Dimension` described by a single value is assumed to be\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# a `Categorical` dimension. This can be used in `BayesSearchCV`\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# to define subspaces that fix one value, e.g. to choose the\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# model type, see \"sklearn-gridsearchcv-replacement.py\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# for examples.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dimension) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dimension 0. See the documentation of check_dimension for supported values."
     ]
    }
   ],
   "source": [
    "# Example of Usage\n",
    "\n",
    "# Generate a random graph\n",
    "graph = nx.erdos_renyi_graph(10, 0.3)\n",
    "\n",
    "# Compute the Laplacian matrix\n",
    "laplacian = get_laplacian_matrix(graph)\n",
    "\n",
    "# Perform eigendecomposition\n",
    "eigenvectors, eigenvalues = get_eigendecomposition(laplacian)\n",
    "\n",
    "# Define the covariance matrix of the GP\n",
    "kernel = LaplacianGPKernel(laplacian)\n",
    "\n",
    "# Initialize the custom GP with the defined covariance matrix\n",
    "gp = GaussianProcessRegressor(kernel=LaplacianGPKernel)\n",
    "\n",
    "# Initialize a list to store evaluated nodes and corresponding validation metrics\n",
    "evaluated_nodes: List[Any] = []\n",
    "evaluated_metrics: List[float] = []\n",
    "\n",
    "# Run bayesian optimization\n",
    "for _ in range(10):\n",
    "    # Perform Bayesian optimization step with Expected Improvement\n",
    "    result = gp_minimize(lambda x: -objective_function(x), graph.nodes(),\n",
    "                         base_estimator=gp, acq_func=\"EI\", n_calls=1)\n",
    "\n",
    "    # Get the next node to evaluate\n",
    "    next_node = result.x\n",
    "\n",
    "    # Evaluate the objective function on the selected node\n",
    "    validation_metric = objective_function(next_node)\n",
    "\n",
    "    # Update the surrogate model with the new data\n",
    "    evaluated_nodes.append(next_node)\n",
    "    evaluated_metrics.append(validation_metric)\n",
    "    gp.fit(np.array(evaluated_nodes).reshape(-1, 1), evaluated_metrics)\n",
    "\n",
    "# Get the optimal node and validation metric found\n",
    "optimal_node = evaluated_nodes[np.argmin(evaluated_metrics)]\n",
    "optimal_metric = np.min(evaluated_metrics)\n",
    "\n",
    "print(\"Optimal node:\", optimal_node)\n",
    "print(\"Optimal validation metric:\", optimal_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
