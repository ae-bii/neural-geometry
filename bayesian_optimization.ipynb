{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.learning import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Kernel, _check_length_scale\n",
    "from skopt.acquisition import gaussian_ei\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from typing import List, Tuple, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph search space\n",
    "# graph = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function with validation metric\n",
    "def objective_function(params: Any) -> float:\n",
    "    # Train the neural network with the given parameters\n",
    "    validation_metric = train_neural_network(params)\n",
    "    return -validation_metric  # Minimize the negative of the validation metric\n",
    "\n",
    "# Compute the Laplacian matrix of the graph\n",
    "def get_laplacian_matrix(graph: nx.Graph) -> np.ndarray:\n",
    "    # Convert the graph to an adjacency matrix\n",
    "    adjacency_matrix = nx.adjacency_matrix(graph).toarray()\n",
    "    \n",
    "    # Compute the degree matrix\n",
    "    degree_matrix = np.diag(np.sum(adjacency_matrix, axis=1))\n",
    "    \n",
    "    # Compute the Laplacian matrix: L = D - A\n",
    "    laplacian = degree_matrix - adjacency_matrix\n",
    "    \n",
    "    return laplacian\n",
    "\n",
    "# Perform eigendecomposition of the Laplacian matrix\n",
    "def get_eigendecomposition(laplacian: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Compute eigendecomposition: L = U * Lambda * U^T\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(laplacian)\n",
    "    return eigenvectors, np.diag(eigenvalues)\n",
    "\n",
    "# Define the covariance matrix of the GP\n",
    "def compute_covariance_matrix(eigenvectors: np.ndarray, eigenvalues: np.ndarray, beta: float) -> np.ndarray:\n",
    "    # Define the covariance matrix: U * e^(-beta * Lambda) * U^T\n",
    "    covariance_matrix = np.dot(eigenvectors, np.dot(np.exp(-beta * eigenvalues), eigenvectors.T))\n",
    "    return covariance_matrix\n",
    "\n",
    "# Create custom kernel for the GP\n",
    "# https://stackoverflow.com/questions/49188159/how-to-create-a-custom-kernel-for-a-gaussian-process-regressor-in-scikit-learn\n",
    "# https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/gaussian_process/kernels.py#L165\n",
    "class LaplacianGPKernel(Kernel):\n",
    "    def __init__(self, laplacian_matrix: np.ndarray, beta: float):\n",
    "        self.laplacian_matrix = laplacian_matrix\n",
    "        self.beta = beta\n",
    "\n",
    "    def __call__(self, X: np.ndarray, Y: np.ndarray = None) -> np.ndarray:\n",
    "        if Y is None:\n",
    "            Y = X\n",
    "        # Compute the Laplacian-based covariance matrix\n",
    "        v, e = get_eigendecomposition(X)\n",
    "        K = compute_covariance_matrix(v, e, self.beta)\n",
    "        return K\n",
    "\n",
    "    def diag(self, X: np.ndarray) -> np.ndarray:\n",
    "        return np.ones(X.shape[0])\n",
    "\n",
    "    def is_stationary(self) -> bool:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Usage\n",
    "\n",
    "# Generate a random graph\n",
    "graph = nx.erdos_renyi_graph(10, 0.3)\n",
    "\n",
    "# Compute the Laplacian matrix\n",
    "laplacian = get_laplacian_matrix(graph)\n",
    "\n",
    "# Perform eigendecomposition\n",
    "eigenvectors, eigenvalues = get_eigendecomposition(laplacian)\n",
    "\n",
    "# Define the covariance matrix of the GP\n",
    "kernel = LaplacianGPKernel(laplacian)\n",
    "\n",
    "# Initialize the custom GP with the defined covariance matrix\n",
    "gp = GaussianProcessRegressor(kernel=LaplacianGPKernel)\n",
    "\n",
    "# Initialize a list to store evaluated nodes and corresponding validation metrics\n",
    "evaluated_nodes: List[Any] = []\n",
    "evaluated_metrics: List[float] = []\n",
    "\n",
    "# Run bayesian optimization\n",
    "for _ in range(10):\n",
    "    # Perform Bayesian optimization step with Expected Improvement\n",
    "    result = gp_minimize(lambda x: -objective_function(x), graph.nodes(),\n",
    "                         base_estimator=gp, acq_func=\"EI\", n_calls=1)\n",
    "\n",
    "    # Get the next node to evaluate\n",
    "    next_node = result.x\n",
    "\n",
    "    # Evaluate the objective function on the selected node\n",
    "    validation_metric = objective_function(next_node)\n",
    "\n",
    "    # Update the surrogate model with the new data\n",
    "    evaluated_nodes.append(next_node)\n",
    "    evaluated_metrics.append(validation_metric)\n",
    "    gp.fit(np.array(evaluated_nodes).reshape(-1, 1), evaluated_metrics)\n",
    "\n",
    "# Get the optimal node and validation metric found\n",
    "optimal_node = evaluated_nodes[np.argmin(evaluated_metrics)]\n",
    "optimal_metric = np.min(evaluated_metrics)\n",
    "\n",
    "print(\"Optimal node:\", optimal_node)\n",
    "print(\"Optimal validation metric:\", optimal_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
